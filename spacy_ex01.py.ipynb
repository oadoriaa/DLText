{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import thinc\n",
    "import numpy\n",
    "from spacy.pipeline import Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.9'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Example / short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[This is a good sentence.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.SentenceSegmenter at 0x7f09f86bc5c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(u'This is a good sentence.')\n",
    "print([s for s in doc.sents])\n",
    "nlp.create_pipe('sentencizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = Tagger(nlp.vocab)\n",
    "doc = nlp(u\"This is a sentence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This is a sentence."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Example / long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_vectors_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create a pipeline component from a factory.\n",
      "\n",
      "        name (unicode): Factory name to look up in `Language.factories`.\n",
      "        config (dict): Configuration parameters to initialise component.\n",
      "        RETURNS (callable): Pipeline component.\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(nlp.create_pipe.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add a component to the processing pipeline. Valid components are\n",
      "        callables that take a `Doc` object, modify it and return it. Only one\n",
      "        of before/after/first/last can be set. Default behaviour is \"last\".\n",
      "\n",
      "        component (callable): The pipeline component.\n",
      "        name (unicode): Name of pipeline component. Overwrites existing\n",
      "            component.name attribute if available. If no name is set and\n",
      "            the component exposes no name attribute, component.__name__ is\n",
      "            used. An error is raised if a name already exists in the pipeline.\n",
      "        before (unicode): Component name to insert component directly before.\n",
      "        after (unicode): Component name to insert component directly after.\n",
      "        first (bool): Insert component first / not first in the pipeline.\n",
      "        last (bool): Insert component last / not last in the pipeline.\n",
      "\n",
      "        EXAMPLE:\n",
      "            >>> nlp.add_pipe(component, before='ner')\n",
      "            >>> nlp.add_pipe(component, name='custom_name', last=True)\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "print(nlp.add_pipe.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.add_pipe(nlp.create_pipe('sentencizer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A look-up table that allows you to access `Lexeme` objects. The `Vocab`\n",
      "    instance also provides access to the `StringStore`, and owns underlying\n",
      "    C-data that is shared between `Doc` objects.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(nlp.vocab.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1070971, 300)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 1070971, 300\n",
    "nlp.vocab.vectors.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = nlp.vocab.vectors.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data = thinc.extra.datasets.imdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(imdb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Sure, we all like bad movies at one time or another, and we in fact enjoy them, This however, wasn't even a guilty pleasure, it was just crap. Some guy, vince offer, who is conceited enough to make himself the main character while probably got drunk/high--probably both--and thought it was a great idea to make a movie. He then proceeded to show his script to equally high/drunk individuals. Overall, this movie was so bad, predictable, and unoriginal I couldn't get through 20 minutes of it before I turned it off. It makes You Got Served look like Citizen Kane. Bat Man? WTF...Some guy that walks around with a bat, real original. Almost as good as calling him Fat Man, and having a fat guy walk around in a superhero outfit.\",\n",
       " 0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "25000\n",
      "25000\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(imdb_data))\n",
    "print(len(imdb_data[0]))\n",
    "print(len(imdb_data[1]))\n",
    "print(imdb_data[0][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_texts, dev_labels = zip(*imdb_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "print(len(dev_texts))\n",
    "print(len(dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(docs, max_length):\n",
    "    docs = list(docs)\n",
    "    Xs = numpy.zeros((len(docs), max_length), dtype='int32')\n",
    "    for i, doc in enumerate(docs):\n",
    "        j = 0\n",
    "        for token in doc:\n",
    "            vector_id = token.vocab.vectors.find(key=token.orth)\n",
    "            if vector_id >= 0:\n",
    "                Xs[i, j] = vector_id\n",
    "            else:\n",
    "                Xs[i, j] = 0\n",
    "            j += 1\n",
    "            if j >= max_length:\n",
    "                break\n",
    "    return Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xs = get_features(dev_texts,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from spacy.tokens import Token, Span\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "class Countries(object):\n",
    "    name = 'countries'  # component name shown in pipeline\n",
    "\n",
    "    def __init__(self, nlp, label='GPE'):\n",
    "        # request all country data from the API\n",
    "        r = requests.get('https://restcountries.eu/rest/v2/all')\n",
    "        self.countries = {c['name']: c for c in r.json()}  # create dict for easy lookup\n",
    "        # initialise the matcher and add patterns for all country names\n",
    "        self.matcher = PhraseMatcher(nlp.vocab)\n",
    "        self.matcher.add('COUNTRIES', None, *[nlp(c) for c in self.countries.keys()])\n",
    "        self.label = nlp.vocab.strings[label] # get label ID from vocab\n",
    "        # register extensions on the Token\n",
    "        Token.set_extension('is_country', default=False)\n",
    "        Token.set_extension('country_capital')\n",
    "        Token.set_extension('country_latlng')\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        matches = self.matcher(doc)\n",
    "        spans = []  # keep the spans for later so we can merge them afterwards\n",
    "        for _, start, end in matches:\n",
    "            # create Span for matched country and assign label\n",
    "            entity = Span(doc, start, end, label=self.label)\n",
    "            spans.append(entity)\n",
    "            for token in entity:  # set values of token attributes\n",
    "                token._.set('is_country', True)\n",
    "                token._.set('country_capital', self.countries[entity.text]['capital'])\n",
    "                token._.set('country_latlng', self.countries[entity.text]['latlng'])\n",
    "        doc.ents = list(doc.ents) + spans  # overwrite doc.ents and add entities – don't replace!\n",
    "        for span in spans:\n",
    "            span.merge()  # merge all spans at the end to avoid mismatched indices\n",
    "        return doc  # don't forget to return the Doc!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Colombia', 'GPE'), ('Czech Republic', 'GPE')]\n",
      "[('Colombia', 'Bogotá'), ('Czech Republic', 'Prague')]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en')\n",
    "component = Countries(nlp)\n",
    "nlp.add_pipe(component, before='tagger')\n",
    "doc = nlp(u\"Some text about Colombia and the Czech Republic\")\n",
    "\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])\n",
    "# [('Colombia', 'GPE'), ('Czech Republic', 'GPE')]\n",
    "\n",
    "print([(token.text, token._.country_capital) for token in doc if token._.is_country])\n",
    "# [('Colombia', 'Bogotá'), ('Czech Republic', 'Prague')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Countries"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some text about Colombia and the Czech Republic\n"
     ]
    }
   ],
   "source": [
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
